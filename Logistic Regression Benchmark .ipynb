{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c349ff26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0bc641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83ebbea",
   "metadata": {},
   "source": [
    "# Step 1. Cleaning and Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "608aa396",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/data-sample-invoices.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e623fab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26040"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0c3db0",
   "metadata": {},
   "source": [
    "- Integer columns with at least one `NaN` are converted automaticaly by pandas to floatg64.\n",
    "- To allows these columns to be integer and have null values, we convert to 'Int64' dtype (nullable Int array)\n",
    "- Finally, convert to 'category' dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be62851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nature'] = df['nature'].astype('Int64')\n",
    "df['nature'] = df['nature'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "762bd719",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cost_center'] = df['cost_center'].astype('Int64')\n",
    "df['cost_center'] = df['cost_center'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991737a3",
   "metadata": {},
   "source": [
    "### Targets: `nature`, `cost_center`, `prepayment` values in extra_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e99e05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['nature'].unique())  # 172 classes over 26,040 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be815cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['cost_center'].unique())  # 274 classes over 26,040 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df641a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"prepayment\"].replace({\"FALSO\": False, \"VERDADERO\": True}, inplace=True)  # highly skewed; 26,005 is False: 99.8%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151f4fc3",
   "metadata": {},
   "source": [
    "#### Benchmark con Logistic regression o Multinomial?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6c7e476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counterparty_name</th>\n",
       "      <th>counterparty_alias</th>\n",
       "      <th>counterparty_rfc</th>\n",
       "      <th>descriptions</th>\n",
       "      <th>id</th>\n",
       "      <th>prepayment</th>\n",
       "      <th>nature</th>\n",
       "      <th>cost_center</th>\n",
       "      <th>all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>REMAPA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REM120119US5</td>\n",
       "      <td>HONORARIOS POR GESTI&amp;Oacute;N PARA TRABAJOS E...</td>\n",
       "      <td>45765920</td>\n",
       "      <td>FALSO</td>\n",
       "      <td>3461</td>\n",
       "      <td>10031</td>\n",
       "      <td>REMAPA REM120119US5  HONORARIOS POR GESTI&amp;Oacu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     counterparty_name counterparty_alias counterparty_rfc                                       descriptions        id prepayment nature cost_center                                           all_text\n",
       "1344            REMAPA                NaN     REM120119US5   HONORARIOS POR GESTI&Oacute;N PARA TRABAJOS E...  45765920      FALSO   3461       10031  REMAPA REM120119US5  HONORARIOS POR GESTI&Oacu..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[[1344]]\n",
    "# in this sample, text is not provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec871411",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('text', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7778cae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['all_text'] = df['counterparty_name'] + ' ' + df['counterparty_rfc'] + ' ' + df['descriptions']  # tokenize and vectorize\n",
    "df['all_text'] = df['all_text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5581a27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def convertAccented(text, pattobj):\n",
    "    '''\n",
    "    Restores characters from a normalized, lowercase text\n",
    "    like \"&oacute;\" into \"ó\"\n",
    "    '''\n",
    "    accented = {\n",
    "        'a':'á',\n",
    "        'e':'é',\n",
    "        'i':'í',\n",
    "        'o': 'ó',\n",
    "        'u':'ú'\n",
    "    }\n",
    "    \n",
    "    def accentRepl(matchobj):\n",
    "        letter = matchobj.group(1)\n",
    "        return accented[letter]\n",
    "    \n",
    "    text = pattobj.sub(accentRepl, text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "19180658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeTextColumn(dataframe):\n",
    "    # lowercase and remove invalid characters from `all_text` column\n",
    "    patt = r'&([aeiou])acute;'  # vowel is captured by group 1\n",
    "    rgx = re.compile(patt)\n",
    "    dataframe['all_text'] = dataframe['all_text'].apply( lambda x: convertAccented(x.lower(), rgx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "67814134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'remapa rem120119us5  honorarios por gestión para trabajos especializados cc 10031 proveedor: 326824'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patt = r'&([aeiou])acute;'  # vowel is captured by group 1\n",
    "rgx = re.compile(patt)\n",
    "\n",
    "convertAccented(df['all_text'][1344].lower(), rgx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0df252dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizeTextColumn(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076ee00a",
   "metadata": {},
   "source": [
    "Para este punto tenemos las features x1, x2,..,xp concatenadas como un solo texto.\n",
    "Tenemos que vectorizar el texto de cada observación antes de pasarlo a un algoritmo de clasificación.\n",
    "\n",
    "En scikit-learn, los vectorizers implementan tokenización. \n",
    "\n",
    "##### Limpieza previa del Texto\n",
    "1. Una buena práctica es quitar la puntuación primero.\n",
    "2. En español, quizá no deberíamos quitar acentos (aunque a veces no vienen con ellos nisiquiera)\n",
    "3. Queremos obtener únicamente palabras relevantes que existen en el español? \n",
    "4. Sin limpieza, ¿cuáles son los tokens más frecuentes? ¿Qué tanto poder de predicción tiene un RFC?\n",
    "5. Usar una función previa o aprovechar los parámetros de un Vectorizer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6137a13b",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/0.15/modules/feature_extraction.html#text-feature-extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0a7ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
